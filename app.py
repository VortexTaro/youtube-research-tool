import streamlit as st
import os
import re
from datetime import datetime
from scraper_service import (
    search_youtube,
    get_channel_details,
    get_transcript,
    get_transcript_by_url,
    extract_transcript_text,
)

# --- å®šæ•° ---
SEARCH_LIMIT = 20
TRANSCRIPTS_DIR = os.path.join(os.path.dirname(__file__), '..', 'transcripts')
os.makedirs(TRANSCRIPTS_DIR, exist_ok=True)

# --- Streamlit App ---

st.set_page_config(layout="wide", initial_sidebar_state="expanded", page_title="YouTube Research Tool")
st.title("YouTube Research Tool")
st.caption("å·¦ä¸Šã®ä¸‰æœ¬ç·šã§ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’é–‹ã‘ã‚‹ã‚ˆã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ã‚‚ãƒšãƒ¼ã‚¸ç§»å‹•ã§ãã‚‹ã€‚")

# æ˜ç¤ºãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ãŒè¦‹ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
nav_col1, nav_col2 = st.columns([1, 3])
with nav_col1:
    if st.button("ä»»æ„URLã®ä¸€æ‹¬æ–‡å­—èµ·ã“ã—ã‚’é–‹ã"):
        try:
            st.switch_page("pages/01_Bulk_URL_Transcriber.py")
        except Exception:
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®Pagesã‹ã‚‰ã€ä»»æ„URLã®ä¸€æ‹¬æ–‡å­—èµ·ã“ã—ã€ã‚’é¸ã‚“ã§ã­ã€‚")

# æ—§å¼ãƒªãƒ³ã‚¯ï¼ˆä¸€éƒ¨ç’°å¢ƒã§æ©Ÿèƒ½ã—ãªã„ã“ã¨ãŒã‚ã‚‹ãŸã‚ãƒœã‚¿ãƒ³ã‚’å„ªå…ˆï¼‰
try:
    st.page_link("pages/01_Bulk_URL_Transcriber.py", label="ä»»æ„URLã®ä¸€æ‹¬æ–‡å­—èµ·ã“ã—ã¸ â†’", icon="ğŸ—‚ï¸")
except Exception:
    pass

# --- Session Stateã®åˆæœŸåŒ– ---
if "videos" not in st.session_state:
    st.session_state.videos = None
if "error" not in st.session_state:
    st.session_state.error = None
if "last_keyword" not in st.session_state:
    st.session_state.last_keyword = ""

# --- UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ ---
search_keyword = st.text_input("Enter search keyword", value=st.session_state.get("last_keyword", ""))

if st.button("Search"):
    if search_keyword:
        # æ–°ã—ã„æ¤œç´¢ã®ãŸã³ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state.videos = None
        st.session_state.error = None
        st.session_state.last_keyword = search_keyword

        with st.spinner("Searching for videos..."):
            try:
                # 1. å‹•ç”»ã‚’æ¤œç´¢
                search_results = search_youtube(search_keyword, limit=SEARCH_LIMIT)

                # 2. APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
                if isinstance(search_results, str):  # APIãŒã‚¨ãƒ©ãƒ¼æ–‡å­—åˆ—ã‚’è¿”ã—ãŸå ´åˆ
                    st.session_state.error = search_results
                    st.session_state.videos = []
                    with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šæ¤œç´¢ã‚¨ãƒ©ãƒ¼è©³ç´°", expanded=True):
                        st.code(search_results)

                # æ­£å¸¸ã«å®ç®±ï¼ˆè¾æ›¸å‹ï¼‰ãŒè¿”ã£ã¦ããŸå ´åˆã®å‡¦ç†
                elif search_results and isinstance(search_results, dict) and 'videos' in search_results:
                    video_list = search_results.get('videos', [])
                    channel_list = search_results.get('channels', [])

                    # ãƒãƒ£ãƒ³ãƒãƒ«IDã‚’ã‚­ãƒ¼ã¨ã—ã¦è³¼èª­è€…æ•°ã‚’æŒã¤è¾æ›¸ï¼ˆãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰ã‚’ä½œæˆ
                    channel_subscribers = {c.get('id'): c.get('subscriberCountText', 'N/A') for c in channel_list if isinstance(c, dict)}

                    if not video_list:
                        st.session_state.videos = []
                    else:
                        enriched_videos = []
                        for video in video_list:
                            if not isinstance(video, dict):
                                continue

                            # ä½œæˆã—ãŸãƒ«ãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰è³¼èª­è€…æ•°ã‚’åŠ¹ç‡çš„ã«å–å¾—
                            channel_id = video.get('channel', {}).get('id')
                            subscriber_count = channel_subscribers.get(channel_id, 'N/A')
                            video['channel_details'] = {'subscriberCountText': subscriber_count}
                            enriched_videos.append(video)

                        st.session_state.videos = enriched_videos
                        st.success("All video details loaded!")

                else: # æ¤œç´¢çµæœãŒç©ºã€ã¾ãŸã¯äºˆæœŸã—ãªã„å½¢å¼ã ã£ãŸå ´åˆ
                    st.session_state.videos = []
                    with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šæ¤œç´¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹(ä¸æ˜å½¢å¼)", expanded=False):
                        st.write(type(search_results).__name__)
                        st.json(search_results)

            except Exception as e:
                st.session_state.error = f"An unexpected error occurred: {e}"
                st.session_state.videos = []
                with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šæ¤œç´¢ä¾‹å¤–è©³ç´°", expanded=True):
                    st.exception(e)
    else:
        st.warning("Please enter a keyword to search.")


# --- çµæœè¡¨ç¤º ---

# ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è¡¨ç¤º
if st.session_state.get("error"):
    st.error(st.session_state.error)

# æ¤œç´¢çµæœï¼ˆå‹•ç”»ãƒªã‚¹ãƒˆï¼‰ãŒã‚ã‚Œã°è¡¨ç¤º
if st.session_state.get("videos") is not None:
    videos = st.session_state.videos
    if not videos:
        st.info("No videos found.")
    else:
        st.write(f"Found {len(videos)} videos.")
        for i, video in enumerate(videos):
            st.write("---")
            col1, col2 = st.columns([1, 4])

            with col1:
                thumbnail_url = video.get("thumbnail")
                if thumbnail_url and isinstance(thumbnail_url, str):
                    st.image(thumbnail_url, width=160)
                else:
                    st.image("https://via.placeholder.com/160x90.png?text=No+Thumbnail", width=160)

            with col2:
                title = video.get('title', 'No Title')
                url = video.get('url', '#')
                channel_name = video.get('channel', {}).get('title', 'N/A')
                view_count = video.get('viewCountText', 'N/A')
                published_date = video.get('publishedTimeText', 'N/A')
                # ãƒãƒ£ãƒ³ãƒãƒ«è©³ç´°ã‹ã‚‰è³¼èª­è€…æ•°ã‚’å–å¾—
                subscriber_count = video.get('channel_details', {}).get('subscriberCountText', 'N/A')

                st.subheader(f"{i + 1}. {title}")
                st.caption(f"**Channel:** {channel_name} | **Subscribers:** {subscriber_count} | **Views:** {view_count} | **Uploaded:** {published_date}")
                st.caption(f"**URL:** {url}")

                if st.button("Download Transcript", key=f"download_{i}"):
                    with st.spinner(f"Downloading transcript for '{title[:30]}...'"):
                        # è¨€èªã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆç°¡æ˜“ï¼‰ã€‚å¿…è¦ãªã‚‰UIã«æ˜‡æ ¼å¯èƒ½
                        transcript_data = None
                        try:
                            transcript_data = get_transcript(url, hl="ja", gl="JP")
                        except Exception as e:
                            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¾‹å¤–è©³ç´°", expanded=True):
                                st.exception(e)

                        # transcriptæŠ½å‡ºï¼ˆAPIã®å½¢çŠ¶å·®ã‚’å¸åï¼‰
                        transcript_text = extract_transcript_text(transcript_data) if isinstance(transcript_data, dict) else None
                        
                        if transcript_text:
                            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ã‚µãƒ‹ã‚¿ã‚¤ã‚º
                            safe_title = re.sub(r'[\\/*?:"<>|]', "", title)
                            filename = f"{safe_title}_transcript.txt"
                            filepath = os.path.join(TRANSCRIPTS_DIR, filename)

                            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä½œæˆ
                            download_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                            header = (
                                f"Title: {title}\n"
                                f"Channel: {channel_name}\n"
                                f"Subscribers: {subscriber_count}\n"
                                f"Views: {view_count}\n"
                                f"Published: {published_date}\n"
                                f"URL: {url}\n"
                                f"Downloaded At: {download_date}\n"
                                f"--- START TRANSCRIPT ---\n\n"
                            )
                            full_content = header + transcript_text

                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã®ã¿
                            st.download_button(
                                label="ã“ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=full_content,
                                file_name=filename,
                                mime="text/plain",
                                key=f"dl_{i}"
                            )
                        else:
                            st.error("Could not retrieve transcript for this video.")
                            with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šAPIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆRawï¼‰", expanded=True):
                                st.json(transcript_data)

# --- ãƒãƒ«ã‚¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
if st.session_state.get("videos"):
    st.write("---")
    st.header("Bulk Download")
    if st.button("Download All Transcripts"):
        all_transcripts_content = []
        bulk_progress = st.progress(0)
        bulk_status = st.empty()

        for i, video in enumerate(st.session_state.videos):
            title = video.get('title', 'No Title')
            url = video.get('url', '#')
            bulk_status.text(f"Downloading transcript for '{title[:30]}...' ({i+1}/{len(st.session_state.videos)})")
            transcript_data = get_transcript(url)
            transcript_text = extract_transcript_text(transcript_data) if isinstance(transcript_data, dict) else None
            
            if transcript_text:
                channel_name = video.get('channel', {}).get('title', 'N/A')
                view_count = video.get('viewCountText', 'N/A')
                subscriber_count = video.get('channel_details', {}).get('subscriberCountText', 'N/A')
                published_date = video.get('publishedTimeText', 'N/A')
                download_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                header = (
                    f"--- Video {i+1} ---\n"
                    f"Title: {title}\n"
                    f"Channel: {channel_name}\n"
                    f"Subscribers: {subscriber_count}\n"
                    f"Views: {view_count}\n"
                    f"Published: {published_date}\n"
                    f"URL: {url}\n"
                    f"Downloaded At: {download_date}\n"
                    f"--- START TRANSCRIPT ---\n\n"
                )
                all_transcripts_content.append(header + transcript_text + "\n\n")
            bulk_progress.progress((i+1)/len(st.session_state.videos))

        if all_transcripts_content:
            combined_content = "".join(all_transcripts_content)
            keyword = st.session_state.last_keyword
            safe_keyword = re.sub(r'[\\/*?:"<>|]', "", keyword)
            filename = f"Bulk_{safe_keyword}_transcripts.txt"
            filepath = os.path.join(TRANSCRIPTS_DIR, filename)

            with open(filepath, "w", encoding="utf-8") as f:
                f.write(combined_content)

            bulk_status.success(f"All transcripts saved to: {filepath}")
            # ãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ç›´æ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                label="ã™ã¹ã¦ã¾ã¨ã‚ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=combined_content,
                file_name=filename,
                mime="text/plain"
            )
        else:
            bulk_status.error("No transcripts could be downloaded.") 